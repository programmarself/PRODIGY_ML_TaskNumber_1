{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./eda'):\n",
    "    os.mkdir('./eda')\n",
    "\n",
    "#  Path to the test data\n",
    "TEST_PATH = '../data/Genre Classification Dataset/test_data_solution.txt'\n",
    "# ID ::: TITLE ::: GENRE ::: DESCRIPTION\n",
    "TRAIN_PATH = '../data/Genre Classification Dataset/train_data.txt'\n",
    "\n",
    "# Read the data\n",
    "train = pd.read_csv(TRAIN_PATH, sep=':::', names=[\n",
    "    'id', 'title', 'genre', 'description'], engine='python')\n",
    "test = pd.read_csv(TEST_PATH, sep=':::', names=[\n",
    "    'id', 'title', 'genre', 'description'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values - visualize them appropriately - and handle them appropriately.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#  Visualize the missing values\n",
    "sns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "plt.title('Missing values in train data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the distribution of genres in the dataset. Are there any imbalanced classes?\n",
    "\n",
    "#  Visualize the distribution of genres\n",
    "sns.countplot(x='genre', data=train)\n",
    "\n",
    "#  Rotate the xticks\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of genres')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly some of the genres are more common than others. The most common genre is Drama, followed by Documentary, Comedy, Thriller, and Action. The least common genre is War, followed by History, and Western. The dataset is imbalanced, and we will need to take this into account when training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for the descriptions of movies for each genre to get a sense of the most common words used to describe movies in that genre.\n",
    "\n",
    "#  Create a word cloud for each genre\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "genres = train['genre'].unique()\n",
    "for genre in genres:\n",
    "    text = train[train['genre'] == genre]['description'].values\n",
    "    wordcloud = WordCloud(width=800, height=400).generate(str(text))\n",
    "    # Plot the word cloud with good visualization\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.title(f'Word cloud for {genre}')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'./eda/wordcloud_{genre.strip()}.png')\n",
    "    if genre == 'Drama':\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word frequency distribution plot for the descriptions of movies for each genre.\n",
    "\n",
    "#  Create a word frequency distribution plot for each genre - drop the stop words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for genre in genres:\n",
    "    text = train[train['genre'] == genre]['description'].values\n",
    "    word_tokens = word_tokenize(str(text))\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    fdist = FreqDist(filtered_sentence)\n",
    "    fdist.plot(30, cumulative=False)\n",
    "    plt.title(f'Word frequency distribution plot for {genre}')\n",
    "    plt.savefig(f'./eda/word_frequency_distribution_{genre.strip()}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a technique like TF-IDF to identify the most discriminative words for each genre.\n",
    "\n",
    "#  Use TF-IDF to identify the most discriminative words for each genre\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print('Most discriminative words for each genre\\n')\n",
    "for genre in genres:\n",
    "    text = train[train['genre'] == genre]['description'].values\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    features = (vectorizer.get_feature_names_out())\n",
    "    print(f'Genre: {genre}')\n",
    "    for i in X.max(0).toarray()[0].argsort()[-3:][::-1]:\n",
    "        print(features[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a visualization tool like a scatter plot matrix to identify correlations between different genres.\n",
    "\n",
    "#  Use a scatter plot matrix to identify correlations between different genres\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(train['description'])\n",
    "features = (vectorizer.get_feature_names_out())\n",
    "df = pd.DataFrame(X.toarray(), columns=features)\n",
    "df['genre'] = train['genre']\n",
    "sns.pairplot(df, hue='genre')\n",
    "plt.title('Scatter plot matrix')\n",
    "plt.savefig('./eda/scatter_plot_matrix.png')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a few sample movie reviews in each genre to get a sense of the language patterns.\n",
    "\n",
    "#  Create a few sample movie reviews in each genre randomly\n",
    "import numpy as np\n",
    "for genre in genres:\n",
    "    text = train[train['genre'] == genre]['description'].values\n",
    "    print(f'Genre: {genre}')\n",
    "    # Shuffle the text\n",
    "    np.random.shuffle(text)\n",
    "    print(text[0])\n",
    "    print(text[1])\n",
    "    print(text[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5207ace3ef1bc29e8da7fd90c10077a0d054d2756ecb5788c905b459a83b9eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
